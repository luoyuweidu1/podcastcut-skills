<!--
pos: 辅助，提供性能参考和常见问题解决
-->

# 转录最佳实践

> 代码实现见 `../scripts/transcribe.py` 和 `../scripts/generate_transcript.py`

---

## 性能参考

| 音频时长 | 预估处理时间 | 预估句子数 |
|----------|--------------|------------|
| 30 分钟 | ~4 分钟 | ~400 句 |
| 1 小时 | ~8 分钟 | ~850 句 |
| 2 小时 | ~16 分钟 | ~1700 句 |

*测试环境：M1 Mac，CPU 推理，2026-01-31 更新*

---

## 分段 vs 整体转录

| 方式 | 优点 | 缺点 |
|------|------|------|
| **整体转录**（推荐） | 说话人 ID 全程一致 | 内存占用大，2h 音频需 16 分钟 |
| **分段转录** | 避免 OOM | 说话人 ID 每段重置，导致错位 |

**结论**：优先使用整体转录。只有在 OOM 时才考虑分段，且分段后需要手动合并说话人 ID。

---

## 说话人映射确认

FunASR 输出的是说话人 ID（spk0, spk1...），需要确认对应的真实人名。

### 方法：搜索自我介绍短语

```python
# 在转录结果中搜索关键短语
key_phrases = ["我是主播", "我是xxx", "大家好我是", "大家也可以叫我"]
# 根据这些短语确定 spk0/1/2/3 对应的真实人名
```

### 常见问题

1. **同一人被识别为多个 ID**：FunASR 可能把同一人的声音分成多个 ID（如响歌歌 → spk1 + spk3）
   - 解决：在生成审查稿时，将多个 ID 映射到同一人名

2. **ID 数量多于实际人数**：3 人对话可能识别出 4 个 ID
   - 解决：根据自我介绍确认主要说话人，合并多余的 ID

---

## 常见问题

### Q1: 说话人分离不准

**可能原因**：音频太短（< 30s）、说话人超过 10 人、音频质量差、同一人被分成多个 ID

**解决**：
1. 搜索自我介绍短语（"我是主播xxx"）确认正确映射
2. 用户审核时手动调整说话人标签

### Q2: 内存不足（OOM）

**可能原因**：音频太长（> 2.5 小时）

**解决**：
1. 优先尝试整体转录（2 小时音频通常不会 OOM）
2. 如果 OOM，分段处理（每段 30 分钟）
3. ⚠️ 分段后说话人 ID 会不一致，需手动合并

### Q3: 转录失败，没有 sentence_info

**原因**：使用了简化的模型名（如 `model="paraformer-zh"`）

**解决**：必须使用完整模型路径 + VAD + Punc + Speaker 四个模型。直接调用脚本即可。

---

## 音频预处理（可选）

FunASR 可以直接处理 mp3/mp4，但如果遇到问题可以先转为 WAV：

```bash
ffmpeg -i video.mp4 -vn -acodec pcm_s16le -ar 16000 -ac 1 output.wav
```
