<!--
input: sentences.txt（分批，每批 50-80 句）
output: fine_analysis_llm.json 编辑标记
pos: LLM层精剪的prompt模板，供 Step 5b 使用

架构守护者：一旦我被修改，请同步更新：
1. SKILL.md 步骤 5b 的 LLM 层说明
2. 所属文件夹的 README.md
-->

# LLM 精剪 Prompt 模板

## 问题诊断

**LLM 精剪的核心困难**：LLM 天然倾向于"读意思"而非"读表达"——它理解了说话人想表达什么，就自动跳过表面的语气词、重复和口癖。人类读稿时反而因为在"听"文字的节奏，能自然发现这些问题。

**已知漏检分布**（来自用户反馈数据，含 meeting_02 反馈）：
- 重说纠正（self_correction）：占漏检的 **47.8%**（22/46）—— 最大漏检源，需要补充短距离改口
- 句首填充词（"嗯，"/"啊，"/"对，"）：占漏检的 **67%**（历史数据）
- 卡顿词（单字代词重复"我我"/"他他"/"它它" + 句中无义填充音）：占漏检的 **66.3%**（173/261，现已扩展）
- 连续填充词（"这个这个这个"）：占漏检的 ~11%
- 句内重复：占漏检的 ~15%（历史数据）

## 优化策略

### 策略 1：缩小批次 + 强制逐句扫描

**旧方案**：~150 句/批，通读后标记
**新方案**：**50-80 句/批**，对每句强制执行检测清单

### 策略 2：显式检测清单（每句必检）

LLM 分析每一句时，必须按以下清单逐项检查。**不是"找问题"，而是"对每句逐项排查"**。

### 策略 3：两遍 Pass

- **Pass 1**：宁多勿漏，标记所有候选（recall 优先）
- **Pass 2**：对 Pass 1 的标记做确认，去掉误标（precision 修正）

实际操作中可简化为：LLM 先标记，然后 merge_llm_fine.js 和规则层去重。

### 策略 4：输出格式强制逐句报告

要求 LLM 对每句输出状态（clean / has_edits），不能跳过任何句子。这样 LLM 无法"读过就忘"。

---

## Prompt 模板

### 角色设定

```
你是一个播客精剪助手。你的任务是逐句检查转录文本，标记需要删除的口误、语气词和重复。

⚠️ 关键心态：你要像"校对员"一样逐字审读，而不是像"读者"一样理解大意。
每一个"嗯"、"啊"、每一次重复，都不能跳过。
```

### 检测清单（每句必检 8 项）

```
对以下每一句，按顺序检查 8 个检测项。任何一项命中就输出编辑标记。

【检测清单】

1️⃣ 句首填充词（最高优先级！占漏检 67%）
   - 句子前 1-2 个词是否为：嗯、啊、呃、额、对、对呀、哦、噢、哎、诶、唉、欸
   - 后面紧跟实质内容 → 删除填充词（词级删除，不删整句）
   - 例外：纯填充句（如"嗯。"）→ 整句删除，标记为 single_filler
   - 注意："对"作为回应（"对，我也觉得"）→ 根据上下文判断，如果是对前一句的确认则保留

2️⃣ 连续填充词
   - 两个语气词相邻（嗯啊、啊呃、哦嗯）→ 全删
   - 句首 ≥3 个填充词/确认词串（嗯嗯，呃，对，就是...）→ 删除整串

3️⃣ 重说纠正（漏检率最高的语义类型！仔细检查，占漏检 47.8%，需特别关注短距离改口）
   11 种子模式：
   a. 部分重复："你再关你关掉" → 删"你再关"
   b. 否定纠正："它是它不是" → 删"它是"
      例："我是我不是啦"（口语否定纠正，删"我是"）
   c. 词被打断：词说一半 + 重说完整
   d. 半截重说："五年之这五年间" → 删"五年之"
      例："我在我就说" → 删"我在"，保留"我就说"
      例："有一个有一种感觉" → 删"有一个"，保留"有一种感觉"
   e. 指代修正："你的对你对世界的" → 删"你的对"
   f. 粒子结尾假启动：语气词(呢/啊/吧)出现在句中 + 后跟相似内容 → 删到语气词
      例："上一期呢在上一期的超越百岁里边" → 删"上一期呢"
   g. 同头扩展：相同开头出现两次，第二次更完整 → 删第一次
      例："中枢神经系统好像中枢神经系统没办法去调控" → 删"中枢神经系统好像"
      例："关于继续我们继续讲关于这个..." → 删"关于继续"
      例："在人身上在人身上电..." → 删第一个"在人身上"
   h. 近义重述：同一语义不同措辞说了两次 → 删不完整的那次
      例："这个这么也就是说" → 删"这个这么"，保留"也就是说"
   i. 磕绊重启：说到一半卡住，用不同措辞重新说
      例："睡了一睡睡觉一晚上" → 删"睡了一睡"（"睡觉一晚上"是完整重启）
      例："但其实更重要，但其实呃应该是。" → 删"但其实呃应该是。"（残句）
   j. 双重修饰：同一修饰词反复尝试
      例："比较慢的一个比较慢速的一个反应" → 删"比较慢的一个"
      例："分不了分不了那么那么开" → 删到只保留"分不了那么开"
   k. 短距离词序纠正：相邻词语顺序有调整，距离很近（通常 1-3 字间隔）
      例："我们现在时代我们时代现在" → 删"我们现在时代"，保留"我们时代现在"（词序微调）
      例："关键是所以什么的关键" → 删"所以什么的"，保留"关键是关键"（短句中词序重组）

   自查：
   - 句中是否有 ≥2字短语在附近重复出现？（同头扩展的信号）
   - 句中是否有语气词出现在非句尾位置？（假启动的信号）
   - 句中是否有"半截词+完整词"的结构？（磕绊重启的信号）
   - 删掉嫌疑片段后句子是否更通顺？

4️⃣ 句内重复
   - 模式一：A + 中间字(1-3字) + A（如"所以小所以"）
   - 模式二：≥4字短语出现两次，中间夹杂犹豫词（如"和大家都很关心的，很，和大家都很关心的"）
   - 注意排除：列举（任务1任务2）、强调（一个一个地）、叠词（开开心心）

5️⃣ 残句
   - 句子语义/语法不完整（缺宾语/谓语/结尾不自然）
   - 后接静音或重新开始 → 整句删除
   - 以"呢"、"吧"、"的"等虚词结尾但不构成完整句

6️⃣ 纯填充句
   - 整句只有 1-2 个词且全是填充词/确认词（如"嗯。""啊对的嗯。""对对对。"）
   - 无实质信息 → 整句删除，标记为 single_filler 或 residual_sentence

7️⃣ 录制讨论（production talk）
   - 句中讨论录制本身（"这段要不要重录""你声音小了"）
   - 节目开场过渡句（"好的，那么我们就开始了。"）→ 如果是主持人说给嘉宾/团队听的开场指令，而非面向听众的开场白
   - 录制中断对话（"嗯，怎么了？"）→ 偏离主题的录制间互动
   - 如果 5a 已标记 production_talk 则跳过

8️⃣ 卡顿词补充（占漏检 66.3%，需要重点扩展！包含单字代词重复 + 句中无义填充音）
   - 规则层已处理大部分卡顿词，但需要 LLM 层补充：
   - **单字代词重复（高频漏检）**："我我"、"他他"、"它它"、"你你" → 删第一个
     例："然后我我刚刚讲的" → 删第一个"我"
     例："他他控制不了" → 删第一个"他"
     例："它它最先导致产生的" → 删第一个"它"
     例："你你得要注意" → 删第一个"你"

   - **句中无义填充音（新增，漏检主要源！）**：单字语气词"啊/呃/唔"出现在句子中间（非句首非句尾），构不成实际语义
     例："我们的大脑啊它就像是一个雾" → "啊"是中间填充 → 删"啊"，保留"我们的大脑它就像是一个雾"
     例："这个呃工作很辛苦" → "呃"是中间卡顿 → 删"呃"，保留"这个工作很辛苦"
     例："他唔在意这个细节" → "唔"是卡顿音 → 删"唔"，保留"他在意这个细节"
     例："每天啊就是重复的工作" → "啊"夹在主语和谓语之间 → 删"啊"

   - **区分句中填充音 vs 实际用词**：
     - 填充音：有停顿感、不改变句子语义、删掉后更流畅
     - 实际用词："啊！"表感叹、"呃，"表确认等，需要根据上下文判断
     - **判断标准**：如果句子去掉这个音后意思和流畅度都没变 → 删

   - **非标准卡顿**（如"来自来自"被豁免但不应该）
   - **3次以上重复的豁免词**（如"就就就"，虽然"就就"在豁免名单但 ≥3 次仍需删除）

   - **极端重复**（≥3次相同词/短语）：
     例："一个一个一个一个一个特点" → 删多余的重复，保留"一个特点"
     例："更、更、更、更不活跃" → 删多余的"更、"，保留"更不活跃"

   - **"这个"连续重复**：
     例："这个这个这个交感神经系统" → 删多余的"这个"，保留最后一个
     例："这个这个这个急性压力" → 同上

   - **其他单字卡顿音**："嗯嗯"（非句首）、"啦啦"等重复 → 删重复的那个
```

### 输入格式

```
以下是句子 {start_idx}-{end_idx}，请逐句检查：

{句子索引}|{词索引范围}|{说话人}|{文本内容}
...
```

### 输出格式

```json
{
  "batch_range": [start_idx, end_idx],
  "edits": [
    {
      "s": 27,
      "text": "嗯，",
      "type": "filler_start",
      "reason": "句首填充词'嗯'"
    },
    {
      "s": 96,
      "text": "我，因为我，",
      "type": "self_correction",
      "reason": "重说纠正：半截重说，后面'infj是一个'更完整"
    },
    {
      "s": 103,
      "text": "",
      "type": "single_filler",
      "reason": "纯填充句，无实质内容"
    }
  ],
  "scan_summary": {
    "total_sentences": 60,
    "sentences_with_edits": 12,
    "edits_by_type": {
      "filler_start": 5,
      "self_correction": 3,
      "in_sentence_repeat": 2,
      "single_filler": 1,
      "residual_sentence": 1
    }
  }
}
```

### 输出字段说明

| 字段 | 说明 |
|------|------|
| `s` | 句子索引（sentences.txt 的第一列） |
| `text` | 要删除的文本（必须与原文完全匹配，用于时间戳映射） |
| `type` | 编辑类型（见下方类型表） |
| `reason` | 简要理由 |
| `keepText` | （可选）保留的文本（用于 self_correction 等需要说明保留什么的场景） |

### 编辑类型表

| type | 说明 | 删除粒度 |
|------|------|----------|
| `filler_start` | 句首填充词 | 词级（只删填充词+紧随标点） |
| `consecutive_filler` | 连续填充词 | 词级（删整串） |
| `self_correction` | 重说纠正 | 词级（删错误/不完整的部分） |
| `in_sentence_repeat` | 句内重复 | 词级（删第一次出现） |
| `single_filler` | 纯填充句 | 整句 |
| `residual_sentence` | 残句 | 整句 |
| `production_talk` | 录制讨论 | 整句 |
| `stutter` | 卡顿词补充 | 词级 |

---

## 删除边界铁律

1. **删前保后**：后说的通常更完整，删前面保留后面
2. **保留语义连接词**：但、所以、然后、因为——即使出现在卡顿附近也不能删
3. **保留最终完整表达**：卡顿 N 次后最后一次是正确版本
4. **复杂句拆分处理**：一句多处卡顿 → 拆成多个独立编辑
5. **精剪不管内容取舍**：只删口误/语气词/重复，不以"啰嗦"为由删内容

---

## 常见漏检 Pattern（来自用户反馈）

### 句首填充词漏检示例

```
原文：嗯，我觉得这个事情挺重要的。
期望：删除"嗯，" → 输出 {"s": X, "text": "嗯，", "type": "filler_start"}
常见遗漏：LLM 看到"我觉得这个事情挺重要的"就理解了意思，忽略了前面的"嗯，"
```

### 换人后句首填充词漏检示例（高频漏检）

```
上下文：S53 [响歌歌]: 嗯。 → S54 [响歌歌]: 对，谢谢青阳介绍一下你的学习和工作的经历。
期望：删除S54的"对，" → filler_start
常见遗漏：LLM 认为"对"是对前一句的回应，但播客精剪中长句开头的"对，"一律删

上下文：S56 [响歌歌]: 那你是从小就自己特别有主意... → S57 [清扬]: 嗯，呃，其实我觉得并没有。
期望：删除S57的"嗯，" → filler_start（"呃，"由consecutive_filler处理）
常见遗漏：LLM 认为"嗯"是对问题的回应，但回答问题时的"嗯，"在精剪中应删

上下文：S57 [清扬]: ...并没有。 → S58 [清扬]: 对，其实我就是说...
期望：删除S58的"对，" → filler_start
常见遗漏：同一说话人接续句的"对，"是自我肯定口头禅，不是真正回应
```

### 重说纠正漏检示例（占漏检 47.8%，最易遗漏！需特别关注短距离改口）

```
原文：上一期呢在上一期的超越百岁里边
期望：删除"上一期呢" → self_correction (粒子结尾假启动)
常见遗漏：LLM 理解了"在上一期的超越百岁里边"，跳过了前面的假启动

原文：可能这条路，这条路更适合我
期望：删除"可能这条路，" → self_correction/in_sentence_repeat
常见遗漏：LLM 把两个"这条路"理解为强调而非口误

原文：中枢神经系统好像中枢神经系统没办法去呃对它进行一个强有力的调控吧。
期望：删除"中枢神经系统好像" → self_correction (同头扩展)
常见遗漏：LLM 看到两段意思一样就跳过了重复

原文：关于继续我们继续讲关于这个缺乏控制感这个事儿
期望：删除"关于继续" → self_correction (假启动)
常见遗漏：前4字和后面的"我们继续讲关于"语义重叠但形式不完全一样

原文：然后我们睡了一睡睡觉一晚上休息好了之后
期望：删除"睡了一睡" → self_correction (磕绊重启)
常见遗漏："睡了一"看起来是正常表达的开头，LLM 没注意到后面"睡觉一晚上"是重新说的

原文：在人身上在人身上电，不管是电刺激还是磁刺激
期望：删除第一个"在人身上" → self_correction (完全重复)
常见遗漏：完全相同的短语重复，LLM 有时不认为这是口误

[短距离改口漏检示例 - 新增]
原文：我在我就说这个问题很重要
期望：删除"我在" → self_correction (半截重说)
常见遗漏：间隔只有2个字，LLM 没认出"我在...我就说"的修正关系

原文：有一个有一种感觉这个东西不太对
期望：删除"有一个" → self_correction (半截重说)
常见遗漏："一个"和"一种"只差一个字，容易被忽视

原文：这么这样的话就能解决这个问题
期望：删除"这么" → self_correction (词序纠正)
常见遗漏：说话人用不同措辞重新表达，距离近时 LLM 倾向认为是句式变化而非口误

原文：我是我不是个特别自律的人
期望：删除"我是" → self_correction (否定纠正)
常见遗漏：否定修正在口语中很常见，但"我是"看起来像完整句子开头，LLM 容易跳过

原文：我因为我是因为工作太忙了
期望：删除"我因为" → self_correction (原因重述)
常见遗漏：同样的语义用两种措辞说，且距离非常近（2-3字间隔）
```

### 卡顿词漏检示例（代词重复 + 句中填充音 + 极端重复）

```
[单字代词重复]
原文：然后我我刚刚讲的这个顺序呢
期望：删除第一个"我" → stutter (单字代词重复)
常见遗漏：规则层只处理 ≥2字重复，"我我"这种单字代词重复落在规则层和LLM之间

原文：他他控制不了
期望：删除第一个"他" → stutter
原文：它它最先导致产生的就是情绪
期望：删除第一个"它" → stutter
原文：你你得好好听这句话
期望：删除第一个"你" → stutter

[句中无义填充音 - 新增，高频漏检！]
原文：大脑啊它就像是一个雾
期望：删除"啊" → stutter (句中填充音)
常见遗漏：LLM 把"啊"理解为表达语气而忽视，但在播客精剪中这类"啊"是纯卡顿音

原文：这个呃工作很辛苦
期望：删除"呃" → stutter (句中填充音)
常见遗漏："呃"夹在词语间，LLM 容易当作语气词保留

原文：他唔在意这个细节
期望：删除"唔" → stutter (句中卡顿音)
常见遗漏：非标准卡顿音，LLM 容易当作口语表达保留

原文：每天啊就是重复的工作啊日常
期望：删除第一个"啊"（但第二个根据位置判断）→ stutter
常见遗漏：同一个字在不同位置可能语义不同，LLM 需要逐个判断

原文：我们的想法呃就是这样的一个情况
期望：删除"呃" → stutter (句中填充)
常见遗漏：语言上下文中间夹杂的卡顿音经常被忽视

[极端重复]
原文：一个一个一个一个一个特点吧
期望：删除多余重复 → stutter (极端重复)
保留："一个特点吧"

原文：更、更、更、更不活跃、更压抑的
期望：删除前3个"更、" → stutter (极端重复)
保留："更不活跃、更压抑的"

原文：这个这个这个交感神经系统
期望：删除前两个"这个" → consecutive_filler
保留："这个交感神经系统"
```

### 判断技巧

- **强调 vs 口误**：强调通常有语调变化、有意为之；口误通常有停顿、犹豫、后面更完整
- **回应 vs 废话**："嗯"在别人说完话后出现 → 回应（保留）；"嗯"在自己句子开头 → 废话（删除）
- **播客精剪原则：句首"对/嗯/啊"一律删**：即使形式上是回应（如换人后的"对，谢谢"、回答问题时的"嗯，其实我觉得"），在播客精剪中句首单字回应词删掉听感更干净。只有当"对/嗯"本身就是完整语义回复（如"嗯，确实是"中"嗯"表达认同且后面是短句），才考虑保留。长句开头的"对，"/"嗯，"一律标记 filler_start
- **播客自然感 vs 冗余**：单个"嗯"保留，连续多个或每句都有就是冗余

---

## 规则层结果 Review（v6 新增）

LLM 层现在会收到规则层的 `fine_analysis_rules.json`，其中部分编辑标记了 `needsReview: true`。LLM 需要根据语境做最终判断。

### 为什么需要 Review

规则层做确定性 pattern matching（如连续相同词检测），但以下场景需要语义判断：
- **单字高频词 2x**（"我我"、"就就"）：大多数是卡顿，少数是自然口语（如"对对"表示认同回应）
- **高频短语 2x**（"就是就是"、"然后然后"）：大多数是卡顿，少数是修辞（如"怎么怎么做"表示泛指）
- **后缀匹配**（"在这个"+"这个"）：ASR 分词边界导致，需确认确实是重复

### LLM Review 决策

在每批分析时，如果 `fine_analysis_rules.json` 中有当前批次句子的 `needsReview` 编辑，LLM 需要在输出中增加 `rules_review` 字段：

```json
{
  "batch_range": [0, 59],
  "edits": [...],
  "rules_review": [
    {"s": 60, "action": "confirm", "reason": "'在这个这个'确实是卡顿重复"},
    {"s": 137, "action": "confirm", "reason": "'我我到 door dash'是卡顿"},
    {"s": 109, "action": "reject", "reason": "'的一个一个'此处'一个一个'是'逐个'的意思，非卡顿"}
  ],
  "scan_summary": {...}
}
```

### 决策原则

| 场景 | 判断 | 示例 |
|------|------|------|
| 代词/副词卡顿 | ✅ confirm（绝大多数情况） | "我我觉得" → 删第一个"我" |
| 回应性重复 | ❌ reject | "对对，你说得对" → "对对"是认同回应 |
| "一个一个"逐个义 | ❌ reject | "一个一个地解决" → 强调逐一 |
| 泛指修辞 | ❌ reject | "怎么怎么做" → 修辞性泛指 |
| 口语连接词卡顿 | ✅ confirm（大多数） | "就是就是说" → 卡顿 |
| 后缀匹配真重复 | ✅ confirm | "在这个这个ALL IN" → "这个"确实重复 |

**默认倾向**：如果不确定，confirm（删除）。用户反馈表明 2x 重复绝大多数是卡顿，漏删比误删更影响听感。

## SKILL.md 集成指引

Step 5b LLM 层执行时：

1. 读取本模板，理解检测清单
2. 加载用户 editing_rules（如有覆盖参数）
3. **读取 `fine_analysis_rules.json`**，了解规则层已 catch 了什么、哪些需要 review
4. 分批读取 sentences.txt（**50-80 句/批**，不是 150）
5. 对每批执行检测清单 + review 规则层 needsReview 项，输出 JSON
6. 所有批次完成后合并为 `fine_analysis_llm.json`
7. 运行 `merge_llm_fine.js` 与规则层合并（confirmed 的保留，rejected 的移除）

### 批次大小建议

| 音频时长 | 总句数 | 批次大小 | 批次数 |
|----------|--------|----------|--------|
| 30min | ~200 | 50 | 4 |
| 1h | ~400 | 60 | 7 |
| 2h | ~800 | 80 | 10 |

更长的音频可以用更大的批次（80句），因为主要瓶颈是注意力，不是上下文长度。
