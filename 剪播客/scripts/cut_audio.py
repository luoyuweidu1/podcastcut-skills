#!/usr/bin/env python3
"""
æ­¥éª¤8: ä¸€é”®å‰ªè¾‘ç”Ÿæˆç²¾å‰ªç‰ˆ

ç”¨æ³•: python3 cut_audio.py [output_name.mp3] [audio_file] [delete_segments.json]
      python3 cut_audio.py [output_name.mp3] [audio_file] [delete_segments.json] --speakers-json subtitles_words.json
é»˜è®¤:
  - output_name: æ’­å®¢_ç²¾å‰ªç‰ˆ_v1.mp3
  - audio_file: ../1_è½¬å½•/audio.mp3
  - delete_segments: delete_segments.json

v4: å¯é€‰è¯´è¯äººéŸ³é‡å¯¹é½ â€” æ£€æµ‹å„è¯´è¯äººå¹³å‡å“åº¦ï¼Œè¡¥å¿éŸ³é‡å·®å¼‚ï¼ˆæœ€å¤§ +6dBï¼‰ã€‚
v3: è‡ªé€‚åº”æ·¡å…¥æ·¡å‡º â€” æ¯ä¸ªåˆ‡ç‚¹æ ¹æ®ç‰‡æ®µæ—¶é•¿è‡ªåŠ¨åŠ  fadeï¼Œæ¶ˆé™¤æ–­å¥æ„Ÿã€‚
v2: å…ˆè§£ç ä¸º WAV å†åˆ‡å‰²ï¼Œç¡®ä¿é‡‡æ ·çº§ç²¾ç¡®ï¼ˆMP3 -c copy åªæœ‰å¸§çº§ç²¾åº¦ ~26msï¼‰ã€‚
"""

import json
import subprocess
import sys
import os
import re
from collections import defaultdict

# ç¡®ä¿ print å®æ—¶è¾“å‡ºï¼ˆé€šè¿‡ç®¡é“è¿è¡Œæ—¶é»˜è®¤æ˜¯å…¨ç¼“å†²ï¼‰
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)


def calc_fade_duration(segment_duration):
    """
    è‡ªé€‚åº”æ·¡å…¥æ·¡å‡ºæ—¶é•¿ï¼Œå’Œç‰‡æ®µé•¿åº¦æŒ‚é’©ã€‚

    è§„åˆ™ï¼š
    - æçŸ­ç‰‡æ®µ (< 0.3s): ä¸åŠ  fadeï¼ˆå¤ªçŸ­ä¼šå¤±çœŸï¼‰
    - çŸ­ç‰‡æ®µ (0.3-2s):  fade = æ®µé•¿ Ã— 8%ï¼Œæœ€å°‘ 0.03s
    - ä¸­ç‰‡æ®µ (2-8s):    fade = 0.15 ~ 0.25s
    - é•¿ç‰‡æ®µ (> 8s):    fade = 0.3sï¼ˆä¸Šé™ï¼‰
    """
    if segment_duration < 0.3:
        return 0.0
    fade = min(segment_duration * 0.08, 0.3)
    return max(fade, 0.03)


MAX_GAIN_DB = 6.0  # æœ€å¤§å¢ç›Šé™åˆ¶ï¼Œé˜²æ­¢è¿‡åº¦æ”¾å¤§å™ªå£°


def load_speaker_segments(speakers_json_path):
    """
    ä» subtitles_words.json æå–æ¯ä¸ªè¯´è¯äººçš„æ—¶é—´æ®µåˆ—è¡¨ã€‚

    subtitles_words.json æ ¼å¼ï¼š
    [
      {"text": "[éº¦é›…]", "start": 69.4, "end": 69.4, "isSpeakerLabel": true, "speaker": "éº¦é›…"},
      {"text": "å¤§å®¶", "start": 69.5, "end": 69.7, "speaker": "éº¦é›…"},
      {"text": "", "start": 70.5, "end": 71.2, "isGap": true},
      ...
    ]

    è¿”å›: {speaker_name: [(start, end), ...]} â€” æ¯ä¸ªè¯´è¯äººçš„è¿ç»­è¯­éŸ³æ—¶é—´æ®µ
    """
    with open(speakers_json_path) as f:
        words = json.load(f)

    # æŒ‰è¯´è¯äººåˆ†ç»„è¿ç»­è¯ï¼Œåˆå¹¶ä¸ºæ—¶é—´æ®µ
    speaker_segments = defaultdict(list)
    current_speaker = None
    seg_start = None
    seg_end = None

    for w in words:
        if w.get('isGap') or w.get('isSpeakerLabel'):
            continue

        speaker = w.get('speaker')
        if not speaker:
            continue

        start = w.get('start', 0)
        end = w.get('end', 0)

        if speaker == current_speaker and seg_end is not None and start - seg_end < 1.0:
            # åŒä¸€è¯´è¯äººï¼Œé—´éš™ < 1sï¼Œå»¶ç»­å½“å‰æ®µ
            seg_end = end
        else:
            # æ–°è¯´è¯äººæˆ–é—´éš™è¿‡å¤§ï¼Œä¿å­˜ä¸Šä¸€æ®µï¼Œå¼€å§‹æ–°æ®µ
            if current_speaker and seg_start is not None:
                speaker_segments[current_speaker].append((seg_start, seg_end))
            current_speaker = speaker
            seg_start = start
            seg_end = end

    # ä¿å­˜æœ€åä¸€æ®µ
    if current_speaker and seg_start is not None:
        speaker_segments[current_speaker].append((seg_start, seg_end))

    return dict(speaker_segments)


def detect_speaker_loudness(wav_file, speaker_segments):
    """
    ç”¨ ffmpeg volumedetect æ£€æµ‹æ¯ä¸ªè¯´è¯äººçš„å¹³å‡éŸ³é‡ (mean_volume dB)ã€‚

    å¯¹æ¯ä¸ªè¯´è¯äººï¼Œé‡‡æ ·æœ€å¤š 30 ä¸ªæ—¶é—´æ®µï¼ˆé¿å…è¶…é•¿æ’­å®¢è€—æ—¶è¿‡ä¹…ï¼‰ï¼Œ
    ç”¨ ffmpeg æå–ç‰‡æ®µå¹¶æµ‹é‡ mean_volumeã€‚

    è¿”å›: {speaker_name: mean_volume_dB}
    """
    speaker_loudness = {}

    for speaker, segments in speaker_segments.items():
        # é‡‡æ ·ï¼šå–æœ€å¤š 30 æ®µï¼Œå‡åŒ€åˆ†å¸ƒ
        if len(segments) > 30:
            step = len(segments) / 30
            sampled = [segments[int(i * step)] for i in range(30)]
        else:
            sampled = segments

        # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ®µï¼ˆ< 0.3sï¼‰ï¼Œæµ‹é‡ä¸å‡†
        sampled = [(s, e) for s, e in sampled if e - s >= 0.3]

        if not sampled:
            continue

        # å°†å¤šæ®µæ‹¼æˆä¸€ä¸ª ffmpeg æ»¤é•œè¡¨è¾¾å¼ï¼Œä¸€æ¬¡è°ƒç”¨å®Œæˆ
        # ç”¨ aselect é€‰æ‹©å¤šä¸ªæ—¶é—´èŒƒå›´ï¼Œå† volumedetect
        select_parts = []
        for s, e in sampled:
            select_parts.append(f'between(t,{s:.3f},{e:.3f})')

        select_expr = '+'.join(select_parts)
        af = f"aselect='{select_expr}',aresample=async=1,volumedetect"

        cmd = [
            'ffmpeg', '-v', 'info',
            '-i', wav_file,
            '-af', af,
            '-f', 'null', '-'
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        stderr = result.stderr

        # è§£æ mean_volume
        match = re.search(r'mean_volume:\s*([-\d.]+)\s*dB', stderr)
        if match:
            speaker_loudness[speaker] = float(match.group(1))

    return speaker_loudness


def calc_volume_compensation(speaker_loudness):
    """
    ä»¥æœ€å“çš„è¯´è¯äººä¸ºåŸºå‡†ï¼ˆ0dB è¡¥å¿ï¼‰ï¼Œè®¡ç®—å…¶ä»–äººéœ€è¦å¢åŠ çš„ dB å€¼ã€‚
    é™åˆ¶æœ€å¤§å¢ç›Šä¸º MAX_GAIN_DBã€‚

    è¿”å›: {speaker_name: gain_dB}
    """
    if not speaker_loudness:
        return {}

    max_vol = max(speaker_loudness.values())
    compensation = {}

    for speaker, vol in speaker_loudness.items():
        gain = max_vol - vol  # æ­£å€¼ = éœ€è¦å¢ç›Š
        gain = min(gain, MAX_GAIN_DB)
        # ä½äº 0.5dB çš„å·®å¼‚å¿½ç•¥ï¼ˆå¬æ„Ÿä¸Šæ— åŒºåˆ«ï¼‰
        compensation[speaker] = round(gain, 2) if gain >= 0.5 else 0.0

    return compensation


def get_segment_speaker(seg_start, seg_end, speaker_segments):
    """
    ç¡®å®šä¸€ä¸ªä¿ç•™ç‰‡æ®µä¸»è¦å±äºå“ªä¸ªè¯´è¯äººã€‚

    æ–¹æ³•ï¼šè®¡ç®—æ¯ä¸ªè¯´è¯äººåœ¨æ­¤æ—¶é—´æ®µå†…çš„é‡å æ—¶é•¿ï¼Œå–æœ€é•¿è€…ã€‚
    """
    best_speaker = None
    best_overlap = 0

    for speaker, segments in speaker_segments.items():
        overlap = 0
        for s, e in segments:
            # è®¡ç®—é‡å 
            ov_start = max(seg_start, s)
            ov_end = min(seg_end, e)
            if ov_end > ov_start:
                overlap += ov_end - ov_start

        if overlap > best_overlap:
            best_overlap = overlap
            best_speaker = speaker

    return best_speaker


def main():
    # å‚æ•°è§£æï¼šæ”¯æŒä½ç½®å‚æ•° + --speakers-json / --no-fade å¯é€‰å‚æ•°
    positional_args = []
    speakers_json = None
    no_fade = False

    i = 1
    while i < len(sys.argv):
        if sys.argv[i] == '--speakers-json':
            if i + 1 < len(sys.argv):
                speakers_json = sys.argv[i + 1]
                i += 2
            else:
                print("--speakers-json éœ€è¦æŒ‡å®šæ–‡ä»¶è·¯å¾„")
                sys.exit(1)
        elif sys.argv[i] == '--no-fade':
            no_fade = True
            i += 1
        else:
            positional_args.append(sys.argv[i])
            i += 1

    output_name = positional_args[0] if len(positional_args) > 0 else 'æ’­å®¢_ç²¾å‰ªç‰ˆ_v1.mp3'
    audio_file = positional_args[1] if len(positional_args) > 1 else '../1_è½¬å½•/audio.mp3'
    delete_file = positional_args[2] if len(positional_args) > 2 else 'delete_segments.json'

    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(audio_file):
        print(f"æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        sys.exit(1)

    if not os.path.exists(delete_file):
        print(f"æ‰¾ä¸åˆ°åˆ é™¤ç‰‡æ®µæ–‡ä»¶: {delete_file}")
        sys.exit(1)

    if speakers_json and not os.path.exists(speakers_json):
        print(f"æ‰¾ä¸åˆ°è¯´è¯äººæ•°æ®æ–‡ä»¶: {speakers_json}")
        sys.exit(1)

    # è¯»å–åˆ é™¤ç‰‡æ®µï¼ˆæ”¯æŒæ–°æ ¼å¼ {segments: [...], editState: {...}} å’Œæ—§æ ¼å¼ [...]ï¼‰
    with open(delete_file) as f:
        raw = json.load(f)
    delete_segs = raw['segments'] if isinstance(raw, dict) and 'segments' in raw else raw

    # ç”Ÿæˆä¿ç•™ç‰‡æ®µ
    keep_segs = []
    last_end = 0

    for seg in delete_segs:
        if seg['start'] > last_end:
            keep_segs.append((last_end, seg['start']))
        last_end = seg['end']

    # è·å–éŸ³é¢‘æ€»æ—¶é•¿
    result = subprocess.run(
        ['ffprobe', '-v', 'error', '-show_entries',
         'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1',
         audio_file],
        capture_output=True, text=True
    )
    total_duration = float(result.stdout.strip())

    if last_end < total_duration:
        keep_segs.append((last_end, total_duration))

    print(f"ğŸ“Š å‰ªè¾‘ç»Ÿè®¡:")
    print(f"   ä¿ç•™ç‰‡æ®µæ•°: {len(keep_segs)}")
    print(f"   åˆ é™¤ç‰‡æ®µæ•°: {len(delete_segs)}")
    print(f"   åŸå§‹æ—¶é•¿: {int(total_duration // 60)}åˆ†{int(total_duration % 60)}ç§’")
    print("")

    # è§£ç ä¸º WAVï¼ˆé‡‡æ ·çº§ç²¾ç¡®åˆ‡å‰²ï¼ŒMP3 -c copy åªæœ‰å¸§çº§ç²¾åº¦ ~26msï¼‰
    temp_wav = '_source_temp.wav'
    print("ğŸ”Š è§£ç ä¸º WAVï¼ˆç¡®ä¿é‡‡æ ·çº§ç²¾ç¡®åˆ‡å‰²ï¼‰...")
    cmd = [
        'ffmpeg', '-v', 'quiet', '-stats',
        '-i', audio_file,
        '-c:a', 'pcm_s16le',
        '-y', temp_wav
    ]
    subprocess.run(cmd, check=True)
    wav_size_mb = os.path.getsize(temp_wav) / (1024 * 1024)
    print(f"   WAV ä¸´æ—¶æ–‡ä»¶: {wav_size_mb:.0f}MB")
    print("")

    # è¯´è¯äººéŸ³é‡å¯¹é½ï¼ˆå¯é€‰ï¼‰
    speaker_compensation = {}
    speaker_segments_data = {}
    if speakers_json:
        print("ğŸ™ï¸ åˆ†æè¯´è¯äººéŸ³é‡...")
        speaker_segments_data = load_speaker_segments(speakers_json)
        print(f"   æ£€æµ‹åˆ° {len(speaker_segments_data)} ä¸ªè¯´è¯äºº: {', '.join(speaker_segments_data.keys())}")

        speaker_loudness = detect_speaker_loudness(temp_wav, speaker_segments_data)
        for spk, vol in speaker_loudness.items():
            print(f"   {spk}: å¹³å‡éŸ³é‡ {vol:.1f} dB")

        speaker_compensation = calc_volume_compensation(speaker_loudness)
        any_compensation = any(g > 0 for g in speaker_compensation.values())

        if any_compensation:
            print("   éŸ³é‡è¡¥å¿æ–¹æ¡ˆ:")
            for spk, gain in speaker_compensation.items():
                if gain > 0:
                    print(f"     {spk}: +{gain:.1f} dB")
                else:
                    print(f"     {spk}: åŸºå‡†ï¼ˆæ— è¡¥å¿ï¼‰")
        else:
            print("   å„è¯´è¯äººéŸ³é‡å·®å¼‚ < 0.5dBï¼Œæ— éœ€è¡¥å¿")
        print("")

    # ä» WAV æå–ä¿ç•™ç‰‡æ®µ
    has_vol = speaker_compensation and any(g > 0 for g in speaker_compensation.values())
    if no_fade:
        print(f"ğŸ¬ æå–ä¿ç•™ç‰‡æ®µï¼ˆæ— æ·¡å…¥æ·¡å‡º{' + è¯´è¯äººéŸ³é‡å¯¹é½' if has_vol else ''}ï¼‰...")
    elif has_vol:
        print("ğŸ¬ æå–ä¿ç•™ç‰‡æ®µï¼ˆå¸¦è‡ªé€‚åº”æ·¡å…¥æ·¡å‡º + è¯´è¯äººéŸ³é‡å¯¹é½ï¼‰...")
    else:
        print("ğŸ¬ æå–ä¿ç•™ç‰‡æ®µï¼ˆå¸¦è‡ªé€‚åº”æ·¡å…¥æ·¡å‡ºï¼‰...")
    segment_files = []
    fade_count = 0

    for i, (start, end) in enumerate(keep_segs):
        seg_dur = end - start
        output = f'segment_{i:04d}.wav'

        is_first = (i == 0)
        is_last = (i == len(keep_segs) - 1)

        if no_fade:
            # å¾® fade 3msï¼šé˜²æ­¢æ³¢å½¢ä¸è¿ç»­çš„ clickï¼Œä½†ä¸å½±å“è¯­éŸ³
            fade_in_dur = 0.0 if is_first else 0.003
            fade_out_dur = 0.0 if is_last else 0.003
        else:
            fade_in_dur = 0.0 if is_first else calc_fade_duration(seg_dur)
            fade_out_dur = 0.0 if is_last else calc_fade_duration(seg_dur)

        # å®‰å…¨æ£€æŸ¥ï¼šæ·¡å…¥ + æ·¡å‡ºä¸èƒ½è¶…è¿‡ç‰‡æ®µæ€»é•¿çš„ 60%
        if fade_in_dur + fade_out_dur > seg_dur * 0.6:
            ratio = (seg_dur * 0.6) / (fade_in_dur + fade_out_dur)
            fade_in_dur *= ratio
            fade_out_dur *= ratio

        # ç¡®å®šæ­¤ç‰‡æ®µçš„è¯´è¯äººéŸ³é‡è¡¥å¿
        vol_gain = 0.0
        if speaker_compensation and speaker_segments_data:
            seg_speaker = get_segment_speaker(start, end, speaker_segments_data)
            if seg_speaker:
                vol_gain = speaker_compensation.get(seg_speaker, 0.0)

        needs_fade = fade_in_dur > 0 or fade_out_dur > 0
        needs_filter = needs_fade or vol_gain > 0

        if needs_filter:
            # æ„å»ºæ»¤é•œé“¾
            filters = []
            if vol_gain > 0:
                filters.append(f'volume={vol_gain:.2f}dB')
            if fade_in_dur > 0:
                filters.append(f'afade=t=in:d={fade_in_dur:.3f}')
            if fade_out_dur > 0:
                fade_out_start = seg_dur - fade_out_dur
                filters.append(f'afade=t=out:st={fade_out_start:.3f}:d={fade_out_dur:.3f}')

            cmd = [
                'ffmpeg', '-v', 'quiet',
                '-ss', str(start),
                '-i', temp_wav,
                '-t', str(seg_dur),
                '-af', ','.join(filters),
                '-y', output
            ]
            if needs_fade:
                fade_count += 1
        else:
            # ç›´æ¥å¤åˆ¶ï¼ˆæ— éœ€ fade ä¹Ÿæ— éœ€éŸ³é‡è¡¥å¿çš„é¦–å°¾æ®µæˆ–æçŸ­æ®µï¼‰
            cmd = [
                'ffmpeg', '-v', 'quiet',
                '-i', temp_wav,
                '-ss', str(start),
                '-to', str(end),
                '-c', 'copy',
                '-y', output
            ]

        subprocess.run(cmd, check=True)
        segment_files.append(output)

        if (i + 1) % 50 == 0:
            print(f"   å·²æå– {i+1}/{len(keep_segs)} ä¸ªç‰‡æ®µ")

    print(f"âœ… å·²æå–æ‰€æœ‰ {len(keep_segs)} ä¸ªç‰‡æ®µï¼Œ{fade_count} ä¸ªåˆ‡ç‚¹åŠ äº†æ·¡å…¥æ·¡å‡º")
    print("")

    # åˆå¹¶ WAV ç‰‡æ®µ
    print("ğŸ”— åˆå¹¶ç‰‡æ®µ...")
    concat_file = 'concat_list.txt'
    with open(concat_file, 'w') as f:
        for seg_file in segment_files:
            f.write(f"file '{seg_file}'\n")

    temp_concat = '_concat_temp.wav'
    cmd = [
        'ffmpeg', '-v', 'quiet', '-stats',
        '-f', 'concat',
        '-safe', '0',
        '-i', concat_file,
        '-c', 'copy',
        '-y', temp_concat
    ]
    subprocess.run(cmd, check=True)

    # ç¼–ç ä¸º MP3
    print("ğŸ”§ ç¼–ç ä¸º MP3...")
    cmd = [
        'ffmpeg', '-v', 'quiet', '-stats',
        '-i', temp_concat,
        '-c:a', 'libmp3lame', '-b:a', '64k',
        '-y', output_name
    ]
    subprocess.run(cmd, check=True)

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_wav)
    os.remove(temp_concat)
    for seg_file in segment_files:
        os.remove(seg_file)
    os.remove(concat_file)

    print("")
    print(f"âœ… å‰ªè¾‘å®Œæˆ: {output_name}")
    print("")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    result = subprocess.run(
        ['ffprobe', '-v', 'error', '-show_entries',
         'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1',
         output_name],
        capture_output=True, text=True
    )
    final_duration = float(result.stdout.strip())

    original_min = int(total_duration // 60)
    final_min = int(final_duration // 60)
    saved_min = original_min - final_min

    print("ğŸ“ˆ å‰ªè¾‘æ•ˆæœ:")
    print(f"   åŸå§‹æ—¶é•¿: {original_min}åˆ†é’Ÿ")
    print(f"   ç²¾å‰ªæ—¶é•¿: {final_min}åˆ†é’Ÿ")
    print(f"   èŠ‚çœæ—¶é—´: {saved_min}åˆ†é’Ÿ ({saved_min/original_min*100:.1f}%)")


if __name__ == '__main__':
    main()
