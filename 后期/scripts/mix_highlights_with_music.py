#!/usr/bin/env python3
"""
é‡‘å¥ç‰‡æ®µ + èƒŒæ™¯éŸ³ä¹æ··åˆè„šæœ¬

å°†é«˜äº®ç‰‡æ®µå åŠ åœ¨è¿ç»­èƒŒæ™¯éŸ³ä¹ä¸Šï¼Œäººå£°å‡ºç°æ—¶éŸ³ä¹è‡ªåŠ¨é™ä½ã€‚
è§£å†³é—®é¢˜ï¼šé‡‘å¥æ²¡æœ‰èƒŒæ™¯éŸ³ä¹å¬èµ·æ¥çªå…€ã€‚

ç”¨æ³•:
  python3 mix_highlights_with_music.py \
    --theme theme_song.mp3 \
    --clips clip1.mp3 clip2.mp3 clip3.mp3 \
    --output intro_complete.wav \
    [--intro-dur 10]       ç‰‡å¤´çº¯éŸ³ä¹æ—¶é•¿ï¼ˆé»˜è®¤10sï¼‰
    [--gap-dur 5]          ç‰‡æ®µé—´è¿‡æ¸¡æ—¶é•¿ï¼ˆé»˜è®¤5sï¼‰
    [--outro-dur 9]        å°¾å£°è¿‡æ¸¡åˆ°æ­£æ–‡æ—¶é•¿ï¼ˆé»˜è®¤9sï¼‰
    [--music-vol 0.16]     äººå£°æ—¶èƒŒæ™¯éŸ³ä¹éŸ³é‡ï¼ˆé»˜è®¤0.16=çº¦8%å¬æ„Ÿï¼‰
    [--voice-gain 2.0]     äººå£°å¢ç›Šå€æ•°ï¼ˆé»˜è®¤2.0ï¼‰
    [--fade-transition 1.5] éŸ³ä¹å‡é™æ¸å˜æ—¶é•¿ï¼ˆé»˜è®¤1.5sï¼‰

è¾“å‡º:
  intro_complete.wav - å®Œæ•´ç‰‡å¤´ï¼ˆè¿ç»­éŸ³ä¹ + äººå£°å åŠ ï¼‰

åŸç†:
  1. è®¡ç®—æ€»æ—¶é•¿å’Œå„æ—¶é—´ç‚¹
  2. åˆ›å»ºè¿ç»­èƒŒæ™¯éŸ³ä¹è½¨ï¼ˆvolume expression åŠ¨æ€è°ƒéŸ³é‡ï¼‰
  3. é€ä¸ªå åŠ äººå£°ï¼ˆamerge+panï¼Œä¸ç”¨ amixï¼ï¼‰
  4. æ··åˆéŸ³ä¹è½¨ + äººå£°è½¨
"""

import argparse
import json
import os
import subprocess
import sys
import tempfile


def get_duration(filepath):
    """è·å–éŸ³é¢‘æ—¶é•¿"""
    result = subprocess.run(
        ['ffprobe', '-v', 'error', '-show_entries',
         'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1',
         filepath],
        capture_output=True, text=True
    )
    return float(result.stdout.strip())


def check_volume(filepath):
    """æ£€æŸ¥éŸ³é¢‘éŸ³é‡ï¼Œè¿”å› max_volume (dB)"""
    result = subprocess.run(
        ['ffmpeg', '-i', filepath, '-af', 'volumedetect', '-f', 'null', '-'],
        capture_output=True, text=True
    )
    for line in result.stderr.split('\n'):
        if 'max_volume' in line:
            val = line.split('max_volume:')[1].strip().split(' ')[0]
            return float(val)
    return -999


def build_volume_expression(timeline, music_vol, fade_dur):
    """
    æ„å»º volume=eval=frame çš„åŠ¨æ€éŸ³é‡è¡¨è¾¾å¼ã€‚

    timeline: [(start, end, vol), ...] å„æ—¶æ®µçš„ç›®æ ‡éŸ³é‡
    music_vol: äººå£°æ—¶çš„èƒŒæ™¯éŸ³é‡ (0-1)
    fade_dur: éŸ³é‡æ¸å˜æ—¶é•¿ (ç§’)
    """
    # æ’åºæ—¶é—´çº¿
    timeline.sort(key=lambda x: x[0])

    # æ„å»º if-else åµŒå¥—è¡¨è¾¾å¼
    parts = []
    for i, (start, end, vol) in enumerate(timeline):
        if i == 0 and start > 0:
            # ç‰‡å¤´åŒºåŸŸï¼ˆstart ä¹‹å‰ï¼‰
            parts.append(f"if(lt(t,{start:.3f}),1.0,")

        if vol < 1.0:
            # äººå£°åŒºåŸŸï¼šæ¸å…¥åˆ°ä½éŸ³é‡
            fade_in_end = start + fade_dur
            fade_out_start = end
            fade_out_end = end + fade_dur

            # æ¸å…¥ä½éŸ³é‡
            parts.append(
                f"if(lt(t,{fade_in_end:.3f}),"
                f"1.0-(t-{start:.3f})/{fade_dur:.3f}*(1.0-{music_vol}),"
            )
            # ä¿æŒä½éŸ³é‡
            parts.append(
                f"if(lt(t,{fade_out_start:.3f}),{music_vol},"
            )
            # æ¸å‡ºæ¢å¤
            parts.append(
                f"if(lt(t,{fade_out_end:.3f}),"
                f"{music_vol}+(t-{fade_out_start:.3f})/{fade_dur:.3f}*(1.0-{music_vol}),"
            )
        else:
            parts.append(f"if(lt(t,{end:.3f}),1.0,")

    # æœ€åä¸€æ®µ
    parts.append("1.0")
    # å…³é—­æ‰€æœ‰æ‹¬å·
    parts.append(")" * (len(parts) - 1))

    return "".join(parts)


def main():
    parser = argparse.ArgumentParser(description='é‡‘å¥ç‰‡æ®µ + èƒŒæ™¯éŸ³ä¹æ··åˆ')
    parser.add_argument('--theme', required=True, help='ä¸»é¢˜æ›²æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--clips', nargs='+', required=True, help='é«˜äº®ç‰‡æ®µæ–‡ä»¶è·¯å¾„åˆ—è¡¨')
    parser.add_argument('--output', default='intro_complete.wav', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--intro-dur', type=float, default=10, help='ç‰‡å¤´çº¯éŸ³ä¹æ—¶é•¿(s)')
    parser.add_argument('--gap-dur', type=float, default=5, help='ç‰‡æ®µé—´è¿‡æ¸¡æ—¶é•¿(s)')
    parser.add_argument('--outro-dur', type=float, default=9, help='å°¾å£°è¿‡æ¸¡åˆ°æ­£æ–‡æ—¶é•¿(s)')
    parser.add_argument('--music-vol', type=float, default=0.08, help='äººå£°æ—¶èƒŒæ™¯éŸ³ä¹éŸ³é‡(0-1)')
    parser.add_argument('--voice-gain', type=float, default=2.0, help='äººå£°å¢ç›Šå€æ•°')
    parser.add_argument('--fade-transition', type=float, default=1.5, help='éŸ³ä¹å‡é™æ¸å˜æ—¶é•¿(s)')
    parser.add_argument('--theme-start', type=float, default=0, help='ä¸»é¢˜æ›²æˆªå–èµ·ç‚¹(s)')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(args.theme):
        print(f"âŒ æ‰¾ä¸åˆ°ä¸»é¢˜æ›²: {args.theme}")
        sys.exit(1)
    for clip in args.clips:
        if not os.path.exists(clip):
            print(f"âŒ æ‰¾ä¸åˆ°ç‰‡æ®µ: {clip}")
            sys.exit(1)

    # è·å–å„ç‰‡æ®µæ—¶é•¿
    clip_durations = []
    for clip in args.clips:
        dur = get_duration(clip)
        clip_durations.append(dur)
        print(f"   ç‰‡æ®µ: {os.path.basename(clip)} ({dur:.1f}s)")

    # è®¡ç®—æ—¶é—´çº¿
    # ç»“æ„: [ç‰‡å¤´éŸ³ä¹] [ç‰‡æ®µ1+ä½éŸ³ä¹] [è¿‡æ¸¡] [ç‰‡æ®µ2+ä½éŸ³ä¹] [è¿‡æ¸¡] ... [å°¾å£°æ¸å‡º]
    timeline = []  # (start_of_voice, end_of_voice, target_vol)
    cursor = args.intro_dur

    clip_positions = []  # æ¯ä¸ªç‰‡æ®µåœ¨æ—¶é—´è½´ä¸Šçš„ä½ç½® (ms)
    for i, dur in enumerate(clip_durations):
        clip_start = cursor
        clip_end = cursor + dur
        clip_positions.append(clip_start)

        # äººå£°åŒºåŸŸï¼šéŸ³ä¹é™ä½ï¼ˆä»æ¸å˜å¼€å§‹åˆ°æ¸å˜ç»“æŸï¼‰
        timeline.append((clip_start - args.fade_transition, clip_end, args.music_vol))

        cursor = clip_end + args.gap_dur

    total_dur = cursor - args.gap_dur + args.outro_dur
    theme_dur = get_duration(args.theme)

    print(f"\nğŸ“Š æ—¶é—´çº¿:")
    print(f"   ç‰‡å¤´éŸ³ä¹: 0 ~ {args.intro_dur:.1f}s")
    for i, (pos, dur) in enumerate(zip(clip_positions, clip_durations)):
        print(f"   ç‰‡æ®µ{i+1}: {pos:.1f} ~ {pos+dur:.1f}s ({dur:.1f}s)")
        if i < len(clip_durations) - 1:
            gap_start = pos + dur
            print(f"   è¿‡æ¸¡: {gap_start:.1f} ~ {gap_start + args.gap_dur:.1f}s")
    print(f"   å°¾å£°: {cursor - args.gap_dur:.1f} ~ {total_dur:.1f}s")
    print(f"   æ€»æ—¶é•¿: {total_dur:.1f}s")

    if args.theme_start + total_dur > theme_dur:
        print(f"   âš ï¸ ä¸»é¢˜æ›² ({theme_dur:.0f}s) å¯èƒ½ä¸å¤Ÿé•¿ï¼Œå°†è‡ªåŠ¨å¾ªç¯")

    work_dir = tempfile.mkdtemp(prefix='podcastcut_mix_')
    print(f"\nğŸ”§ å·¥ä½œç›®å½•: {work_dir}")

    try:
        # ===== Step 1: åˆ›å»ºè¿ç»­èƒŒæ™¯éŸ³ä¹è½¨ =====
        print("\nğŸµ Step 1: åˆ›å»ºè¿ç»­èƒŒæ™¯éŸ³ä¹è½¨...")

        vol_expr = build_volume_expression(timeline, args.music_vol, args.fade_transition)

        music_bed = os.path.join(work_dir, 'music_bed.wav')
        theme_end = args.theme_start + total_dur
        fade_out_start = total_dur - 3

        af_filter = (
            f"atrim=start={args.theme_start:.3f}:end={theme_end:.3f},"
            f"asetpts=PTS-STARTPTS,"
            f"afade=t=in:st=0:d=2,"
            f"afade=t=out:st={fade_out_start:.3f}:d=3,"
            f"volume=eval=frame:volume='{vol_expr}'"
        )

        cmd = [
            'ffmpeg', '-v', 'warning',
            '-i', args.theme,
            '-af', af_filter,
            '-c:a', 'pcm_s16le', '-ar', '44100', '-ac', '2',
            '-y', music_bed
        ]
        subprocess.run(cmd, check=True)

        # æ£€æŸ¥éŸ³é‡
        vol = check_volume(music_bed)
        print(f"   éŸ³ä¹è½¨: {total_dur:.1f}s, max_volume={vol:.1f}dB")
        if vol < -40:
            print(f"   âš ï¸ éŸ³ä¹è½¨éŸ³é‡å¤ªä½ ({vol:.1f}dB)ï¼Œå¯èƒ½æ˜¯é™éŸ³ï¼æ£€æŸ¥ --theme-start å‚æ•°")

        # ===== Step 2: åˆ›å»ºäººå£°è½¨ =====
        print("\nğŸ¤ Step 2: åˆ›å»ºäººå£°è½¨ï¼ˆamerge+pan é€æ­¥å åŠ ï¼‰...")

        # 2a. åˆ›å»ºé™éŸ³åŸºåº•
        silence = os.path.join(work_dir, 'silence.wav')
        cmd = [
            'ffmpeg', '-v', 'warning',
            '-f', 'lavfi', '-i', f'anullsrc=r=44100:cl=stereo',
            '-t', str(total_dur),
            '-c:a', 'pcm_s16le',
            '-y', silence
        ]
        subprocess.run(cmd, check=True)

        # 2b. é€ä¸ªå åŠ äººå£°
        current_base = silence
        for i, (clip, pos) in enumerate(zip(args.clips, clip_positions)):
            delay_ms = int(pos * 1000)
            step_out = os.path.join(work_dir, f'voice_step{i+1}.wav')

            cmd = [
                'ffmpeg', '-v', 'warning',
                '-i', current_base,
                '-i', clip,
                '-filter_complex',
                f"[1:a]volume={args.voice_gain},adelay={delay_ms}|{delay_ms},apad=whole_dur={total_dur:.3f}[v];"
                f"[0:a][v]amerge=inputs=2,pan=stereo|c0=c0+c2|c1=c1+c3[out]",
                '-map', '[out]',
                '-c:a', 'pcm_s16le',
                '-y', step_out
            ]
            subprocess.run(cmd, check=True)
            print(f"   å åŠ ç‰‡æ®µ{i+1}: delay={delay_ms}ms, gain={args.voice_gain}x")
            current_base = step_out

        voice_track = current_base

        # ===== Step 3: æ··åˆéŸ³ä¹ + äººå£° =====
        print("\nğŸ”— Step 3: æ··åˆéŸ³ä¹è½¨ + äººå£°è½¨...")

        cmd = [
            'ffmpeg', '-v', 'warning',
            '-i', music_bed,
            '-i', voice_track,
            '-filter_complex',
            '[0:a][1:a]amerge=inputs=2,pan=stereo|c0=c0+c2|c1=c1+c3[out]',
            '-map', '[out]',
            '-c:a', 'pcm_s16le',
            '-y', args.output
        ]
        subprocess.run(cmd, check=True)

        # æœ€ç»ˆæ£€æŸ¥
        final_dur = get_duration(args.output)
        final_vol = check_volume(args.output)
        print(f"\nâœ… å®Œæˆ: {args.output}")
        print(f"   æ—¶é•¿: {final_dur:.1f}s, max_volume={final_vol:.1f}dB")

        # è¾“å‡ºæ—¶é—´çº¿ JSONï¼ˆä¾›åç»­æ—¶é—´æˆ³åç§»è®¡ç®—ï¼‰
        timeline_info = {
            'total_duration': round(total_dur, 3),
            'intro_music_end': args.intro_dur,
            'clips': [
                {
                    'file': os.path.basename(clip),
                    'start': round(pos, 3),
                    'end': round(pos + dur, 3),
                    'duration': round(dur, 3)
                }
                for clip, pos, dur in zip(args.clips, clip_positions, clip_durations)
            ],
            'outro_start': round(total_dur - args.outro_dur, 3)
        }
        timeline_path = args.output.replace('.wav', '_timeline.json').replace('.mp3', '_timeline.json')
        with open(timeline_path, 'w') as f:
            json.dump(timeline_info, f, indent=2, ensure_ascii=False)
        print(f"   æ—¶é—´çº¿: {timeline_path}")

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(work_dir, ignore_errors=True)
        print(f"\nğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")


if __name__ == '__main__':
    main()
